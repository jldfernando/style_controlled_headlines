{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d64e246",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-large and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating headlines...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [02:27<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- ROUGE Scores ---\n",
      "Style Model <NEUTRAL>: {'rouge1': np.float64(0.5225898104277085), 'rouge2': np.float64(0.2924609627749377), 'rougeL': np.float64(0.47700224503886224), 'rougeLsum': np.float64(0.47749520313651944)}\n",
      "Style Model <PUNCHY>: {'rouge1': np.float64(0.3903088243572036), 'rouge2': np.float64(0.17477048559896916), 'rougeL': np.float64(0.34522829690827084), 'rougeLsum': np.float64(0.34697396355222204)}\n",
      "Baseline Model vs. REF_NEUTRAL: {'rouge1': np.float64(0.5041873390431714), 'rouge2': np.float64(0.2900979513984313), 'rougeL': np.float64(0.4613982541553338), 'rougeLsum': np.float64(0.46130009518084536)}\n",
      "Baseline Model vs. REF_PUNCHY: {'rouge1': np.float64(0.37547813489239795), 'rouge2': np.float64(0.1709033225922213), 'rougeL': np.float64(0.3420045958200083), 'rougeLsum': np.float64(0.34152744607297775)}\n",
      "\n",
      "--- Training Proxy Style Classifier ---\n",
      "Proxy Style Classifier Accuracy (on human data): 59.32%\n",
      "\n",
      "--- Evaluating Style Accuracy ---\n",
      "Style Model Accuracy for requested style <neutral>: 67.19%\n",
      "Style Model Accuracy for requested style <punchy>: 34.38%\n",
      "\n",
      "Baseline Model Style Distribution:\n",
      "  Predicted <punchy>: 26.56%\n",
      "  Predicted <neutral>: 73.44%\n",
      "\n",
      "--- Evaluating Factuality (NLI) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large-mnli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Factuality (NLI) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Style Model Average Entailment Score for <neutral>: 0.8971\n",
      "Style Model Average Entailment Score for <punchy>: 0.8951\n",
      "Baseline Model Average Entailment Score: 0.9250\n",
      "\n",
      "Evaluation Complete!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import evaluate\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
    "from peft import PeftModel, PeftConfig\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Setup\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "BASE_MODEL_ID = \"google/pegasus-large\"\n",
    "STYLE_ADAPTER_PATH = \"../output/style_model_PEGASUS\"\n",
    "\n",
    "# 1. Load Resources\n",
    "tokenizer = AutoTokenizer.from_pretrained(STYLE_ADAPTER_PATH)\n",
    "base_model = AutoModelForSeq2SeqLM.from_pretrained(BASE_MODEL_ID)\n",
    "base_model.resize_token_embeddings(len(tokenizer))\n",
    "model = PeftModel.from_pretrained(base_model, STYLE_ADAPTER_PATH)\n",
    "model.to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "# Load Test Data\n",
    "test_df = pd.read_csv('../data/processed/test.csv')\n",
    "\n",
    "# 2. Generation Loop\n",
    "print(\"Generating headlines...\")\n",
    "results = []\n",
    "styles = ['neutral', 'punchy']\n",
    "style_tokens = {'neutral': '<neutral>', 'punchy': '<punchy>'}\n",
    "\n",
    "for idx, row in tqdm(test_df.iterrows(), total=len(test_df)):\n",
    "    snippet = row['snippet']\n",
    "    \n",
    "    entry = {'snippet': snippet, 'ref_neutral': row['neutral'], \n",
    "             'ref_punchy': row['punchy']}\n",
    "    \n",
    "    # --- 1. Style-Controlled Model Generation ---\n",
    "    for style in styles:\n",
    "        input_text = f\"{style_tokens[style]} {snippet}\"\n",
    "        inputs = tokenizer(input_text, return_tensors=\"pt\").to(DEVICE)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            if style == 'punchy':\n",
    "                outputs = model.generate(\n",
    "                    **inputs,\n",
    "                    max_new_tokens=64,\n",
    "                    do_sample=True,             # Use sampling\n",
    "                    top_p=0.9,                  # Nucleus sampling\n",
    "                    temperature=0.8,            # High temperature for creativity\n",
    "                    num_return_sequences=1      # Ensure you only get one output\n",
    "                )\n",
    "            else: # neutral style, stick to high-fidelity generation\n",
    "                outputs = model.generate(\n",
    "                    **inputs, \n",
    "                    max_new_tokens=64,\n",
    "                    num_beams=4,\n",
    "                )\n",
    "        \n",
    "        gen_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        entry[f'gen_{style}'] = gen_text\n",
    "        \n",
    "    # --- 2. Baseline Model Generation ---\n",
    "    # Baseline uses just the snippet as input, no style token\n",
    "    baseline_inputs = tokenizer(snippet, return_tensors=\"pt\").to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        baseline_outputs = base_model.generate(**baseline_inputs, max_new_tokens=64) # Uses base_model\n",
    "    \n",
    "    baseline_text = tokenizer.decode(baseline_outputs[0], skip_special_tokens=True)\n",
    "    entry['gen_baseline'] = baseline_text\n",
    "    \n",
    "    results.append(entry)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# 3. Metric 1: ROUGE Score\n",
    "rouge = evaluate.load('rouge')\n",
    "print(\"\\n--- ROUGE Scores ---\")\n",
    "\n",
    "# Style-Controlled Model Scores (Existing)\n",
    "for style in styles:\n",
    "    refs = results_df[f'ref_{style}'].tolist()\n",
    "    preds = results_df[f'gen_{style}'].tolist()\n",
    "    score = rouge.compute(predictions=preds, references=refs)\n",
    "    print(f\"Style Model <{style.upper()}>: {score}\")\n",
    "\n",
    "# Baseline Model Scores (NEW)\n",
    "baseline_preds = results_df['gen_baseline'].tolist()\n",
    "\n",
    "# Compare Baseline against NEUTRAL reference\n",
    "refs_neutral = results_df['ref_neutral'].tolist()\n",
    "score_baseline_neutral = rouge.compute(predictions=baseline_preds, references=refs_neutral)\n",
    "print(f\"Baseline Model vs. REF_NEUTRAL: {score_baseline_neutral}\")\n",
    "\n",
    "# Compare Baseline against PUNCHY reference\n",
    "refs_punchy = results_df['ref_punchy'].tolist()\n",
    "score_baseline_punchy = rouge.compute(predictions=baseline_preds, references=refs_punchy)\n",
    "print(f\"Baseline Model vs. REF_PUNCHY: {score_baseline_punchy}\")\n",
    "\n",
    "\n",
    "# 4. Metric 2: Style Accuracy (Simple Proxy Classifier)\n",
    "# We train a quick classifier on the TRAIN set to act as our evaluator\n",
    "print(\"\\n--- Training Proxy Style Classifier ---\")\n",
    "train_df = pd.read_csv('../data/processed/train.csv')\n",
    "train_texts = []\n",
    "train_labels = []\n",
    "\n",
    "# Unpack training data for classifier\n",
    "for _, row in train_df.iterrows():\n",
    "    train_texts.extend([row['neutral'], row['punchy']])\n",
    "    train_labels.extend(['neutral', 'punchy'])\n",
    "\n",
    "# 1. Split the human data for Classifier Training/Testing\n",
    "X_classifier_train, X_classifier_test, y_classifier_train, y_classifier_test = train_test_split(\n",
    "    train_texts, train_labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,5))\n",
    "X_train_vec = vectorizer.fit_transform(X_classifier_train)\n",
    "X_test_vec = vectorizer.transform(X_classifier_test)\n",
    "\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train_vec, y_classifier_train)\n",
    "\n",
    "# 2. Calculate Classifier Accuracy on its own test set\n",
    "y_pred = clf.predict(X_test_vec)\n",
    "classifier_acc = accuracy_score(y_classifier_test, y_pred)\n",
    "\n",
    "print(f\"Proxy Style Classifier Accuracy (on human data): {classifier_acc:.2%}\")\n",
    "\n",
    "# Evaluate Generated Headlines\n",
    "# Evaluate Generated Headlines\n",
    "print(\"\\n--- Evaluating Style Accuracy ---\")\n",
    "\n",
    "# Style-Controlled Model Evaluation (Existing)\n",
    "for style in styles:\n",
    "    gen_texts = results_df[f'gen_{style}'].tolist()\n",
    "    X_test = vectorizer.transform(gen_texts)\n",
    "    preds = clf.predict(X_test)\n",
    "    \n",
    "    # Calculate how many matched the requested style\n",
    "    matches = [1 if p == style else 0 for p in preds]\n",
    "    acc = sum(matches) / len(matches)\n",
    "    print(f\"Style Model Accuracy for requested style <{style}>: {acc:.2%}\")\n",
    "\n",
    "# Baseline Model Evaluation (NEW)\n",
    "baseline_gen_texts = results_df['gen_baseline'].tolist()\n",
    "X_test_baseline = vectorizer.transform(baseline_gen_texts)\n",
    "preds_baseline = clf.predict(X_test_baseline)\n",
    "\n",
    "# Calculate the distribution of predicted styles for the baseline\n",
    "from collections import Counter\n",
    "baseline_style_distribution = Counter(preds_baseline)\n",
    "total_count = len(preds_baseline)\n",
    "\n",
    "print(\"\\nBaseline Model Style Distribution:\")\n",
    "for style, count in baseline_style_distribution.items():\n",
    "    print(f\"  Predicted <{style}>: {count / total_count:.2%}\")\n",
    "\n",
    "# The baseline model isn't requested to be a specific style, so you evaluate its bias.\n",
    "\n",
    "# 5. Metric 3: Factuality (NLI)\n",
    "# Using a small NLI model to check entailment\n",
    "print(\"\\n--- Evaluating Factuality (NLI) ---\")\n",
    "nli_pipeline = pipeline(\"text-classification\", model=\"roberta-large-mnli\", device=0 if DEVICE==\"cuda\" else -1)\n",
    "\n",
    "def get_entailment_score(premise, hypothesis):\n",
    "    # NLI input format: \"Premise </s></s> Hypothesis\" (model specific, but pipeline handles pairs usually)\n",
    "    # roberta-large-mnli labels: CONTRADICTION, NEUTRAL, ENTAILMENT\n",
    "    # We pass text_pair to pipeline\n",
    "    result = nli_pipeline({'text': premise, 'text_pair': hypothesis})\n",
    "    # We want to know if it is NOT contradiction, or strictly entailment\n",
    "    # Let's track Entailment probability\n",
    "    return result['score'] if result['label'] == 'ENTAILMENT' else 0.0\n",
    "\n",
    "print(\"\\n--- Evaluating Factuality (NLI) ---\")\n",
    "\n",
    "# Style-Controlled Model Evaluation (Existing)\n",
    "for style in styles:\n",
    "    scores = []\n",
    "    for _, row in results_df.iterrows():\n",
    "        score = get_entailment_score(row['snippet'], row[f'gen_{style}'])\n",
    "        scores.append(score)\n",
    "    avg_fact = sum(scores)/len(scores)\n",
    "    print(f\"Style Model Average Entailment Score for <{style}>: {avg_fact:.4f}\")\n",
    "\n",
    "# Baseline Model Evaluation (NEW)\n",
    "baseline_scores = []\n",
    "for _, row in results_df.iterrows():\n",
    "    score = get_entailment_score(row['snippet'], row['gen_baseline'])\n",
    "    baseline_scores.append(score)\n",
    "avg_fact_baseline = sum(baseline_scores)/len(baseline_scores)\n",
    "print(f\"Baseline Model Average Entailment Score: {avg_fact_baseline:.4f}\")\n",
    "\n",
    "print(\"\\nEvaluation Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9876f401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>snippet</th>\n",
       "      <th>ref_neutral</th>\n",
       "      <th>ref_punchy</th>\n",
       "      <th>gen_neutral</th>\n",
       "      <th>gen_punchy</th>\n",
       "      <th>gen_baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Young gymnast Maxine Bondoc aims high as she g...</td>\n",
       "      <td>Maxine Bondoc prepares for Junior World Champi...</td>\n",
       "      <td>Dream big: Maxine Bondoc eyes gymnastics glory...</td>\n",
       "      <td>Maxine Bondoc gears up to compete at Junior Wo...</td>\n",
       "      <td>Maxine Bondoc gears up to compete at Junior Wo...</td>\n",
       "      <td>Young gymnast Maxine Bondoc aims high as she g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>The 2023 FIBA World Cup saw record-breaking at...</td>\n",
       "      <td>FIBA World Cup games in PH see high attendance</td>\n",
       "      <td>PH fans flood the arenas — World Cup crowds se...</td>\n",
       "      <td>PH’s FIBA World Cup fever continues: record-br...</td>\n",
       "      <td>Record-breaking attendance at FIBA World Cup 2023</td>\n",
       "      <td>Record-breaking World Cup attendance: Philippi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Far Eastern University’s men’s volleyball team...</td>\n",
       "      <td>FEU men’s volleyball beats NU in big UAAP upset</td>\n",
       "      <td>FEU shocks champs: Tamaraws stun NU in straigh...</td>\n",
       "      <td>Far Eastern defeats NU in men’s volleyball</td>\n",
       "      <td>Far Eastern stuns NU in men’s volleyball</td>\n",
       "      <td>Far Eastern defeats NU in men’s volleyball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Sandro Muhlach filed a sexual assault complain...</td>\n",
       "      <td>Actor Sandro Muhlach accuses former GMA contra...</td>\n",
       "      <td>Sandro Muhlach breaks silence: Files shocking ...</td>\n",
       "      <td>Sandro Muhlach files sexual assault complaint ...</td>\n",
       "      <td>Sandro Muhlach files sexual assault complaint ...</td>\n",
       "      <td>Sandro Muhlach files sexual assault complaint ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Actress Bea Alonzo opened up about how 2024 wa...</td>\n",
       "      <td>Bea Alonzo reflects on a challenging 2024</td>\n",
       "      <td>Bea Alonzo bares her soul — calls 2024 the har...</td>\n",
       "      <td>Bea Alonzo reflects on her toughest year yet</td>\n",
       "      <td>Bea Alonzo reflects on her toughest year yet</td>\n",
       "      <td>Actress Bea Alonzo opens up about how 2024 was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Bella Belen of NU leads the MVP race in UAAP w...</td>\n",
       "      <td>Bella Belen tops stats for MVP in first round ...</td>\n",
       "      <td>Belen blazing: NU’s ace spiker leads MVP race ...</td>\n",
       "      <td>Bella Belen leads MVP race in UAAP women’s vol...</td>\n",
       "      <td>Bella Belen leads MVP race in UAAP women’s vol...</td>\n",
       "      <td>Bella Belen leads MVP race in UAAP women’s vol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>The UAAP named five “Athletes of the Year” for...</td>\n",
       "      <td>UAAP announces five Athletes of the Year, tigh...</td>\n",
       "      <td>UAAP shakes things up: 5 Athletes of the Year ...</td>\n",
       "      <td>Five UAAP Athletes of the Year recognized for ...</td>\n",
       "      <td>Five UAAP athletes named “Athletes of the Year...</td>\n",
       "      <td>UAAP names five “Athletes of the Year” for Sea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Alden Richards revealed he battled deep depres...</td>\n",
       "      <td>Alden Richards opens up about mental health st...</td>\n",
       "      <td>Alden Richards admits: “2024 was my lowest yea...</td>\n",
       "      <td>Alden Richards reveals he battled depression i...</td>\n",
       "      <td>Alden Richards reveals he battled depression i...</td>\n",
       "      <td>Alden Richards reveals he battled depression i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>The Police Criminal Investigation and Detecti...</td>\n",
       "      <td>College Dean Arrested in Maguindanao del Sur O...</td>\n",
       "      <td>Maguindanao Dean Nabbed for Murder of Village ...</td>\n",
       "      <td>College Dean Arrested in Maguindanao Murder Case</td>\n",
       "      <td>College Dean Arrested in Maguindanao Murder Case</td>\n",
       "      <td>CIDG Arrests College Dean in Maguindanao for M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Vice Ganda expressed pride in his partner Ion ...</td>\n",
       "      <td>Vice Ganda proud of Ion Perez’s growth and con...</td>\n",
       "      <td>Vice beams over Ion’s new confidence—says part...</td>\n",
       "      <td>Vice Ganda gushes over partner Ion Perez’s gro...</td>\n",
       "      <td>Vice Ganda gushes over Ion Perez’s growth in s...</td>\n",
       "      <td>Vice also shared how Perez positively influenc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              snippet  \\\n",
       "28  Young gymnast Maxine Bondoc aims high as she g...   \n",
       "31  The 2023 FIBA World Cup saw record-breaking at...   \n",
       "11  Far Eastern University’s men’s volleyball team...   \n",
       "12  Sandro Muhlach filed a sexual assault complain...   \n",
       "15  Actress Bea Alonzo opened up about how 2024 wa...   \n",
       "38  Bella Belen of NU leads the MVP race in UAAP w...   \n",
       "10  The UAAP named five “Athletes of the Year” for...   \n",
       "44  Alden Richards revealed he battled deep depres...   \n",
       "53   The Police Criminal Investigation and Detecti...   \n",
       "26  Vice Ganda expressed pride in his partner Ion ...   \n",
       "\n",
       "                                          ref_neutral  \\\n",
       "28  Maxine Bondoc prepares for Junior World Champi...   \n",
       "31     FIBA World Cup games in PH see high attendance   \n",
       "11    FEU men’s volleyball beats NU in big UAAP upset   \n",
       "12  Actor Sandro Muhlach accuses former GMA contra...   \n",
       "15          Bea Alonzo reflects on a challenging 2024   \n",
       "38  Bella Belen tops stats for MVP in first round ...   \n",
       "10  UAAP announces five Athletes of the Year, tigh...   \n",
       "44  Alden Richards opens up about mental health st...   \n",
       "53  College Dean Arrested in Maguindanao del Sur O...   \n",
       "26  Vice Ganda proud of Ion Perez’s growth and con...   \n",
       "\n",
       "                                           ref_punchy  \\\n",
       "28  Dream big: Maxine Bondoc eyes gymnastics glory...   \n",
       "31  PH fans flood the arenas — World Cup crowds se...   \n",
       "11  FEU shocks champs: Tamaraws stun NU in straigh...   \n",
       "12  Sandro Muhlach breaks silence: Files shocking ...   \n",
       "15  Bea Alonzo bares her soul — calls 2024 the har...   \n",
       "38  Belen blazing: NU’s ace spiker leads MVP race ...   \n",
       "10  UAAP shakes things up: 5 Athletes of the Year ...   \n",
       "44  Alden Richards admits: “2024 was my lowest yea...   \n",
       "53  Maguindanao Dean Nabbed for Murder of Village ...   \n",
       "26  Vice beams over Ion’s new confidence—says part...   \n",
       "\n",
       "                                          gen_neutral  \\\n",
       "28  Maxine Bondoc gears up to compete at Junior Wo...   \n",
       "31  PH’s FIBA World Cup fever continues: record-br...   \n",
       "11         Far Eastern defeats NU in men’s volleyball   \n",
       "12  Sandro Muhlach files sexual assault complaint ...   \n",
       "15       Bea Alonzo reflects on her toughest year yet   \n",
       "38  Bella Belen leads MVP race in UAAP women’s vol...   \n",
       "10  Five UAAP Athletes of the Year recognized for ...   \n",
       "44  Alden Richards reveals he battled depression i...   \n",
       "53   College Dean Arrested in Maguindanao Murder Case   \n",
       "26  Vice Ganda gushes over partner Ion Perez’s gro...   \n",
       "\n",
       "                                           gen_punchy  \\\n",
       "28  Maxine Bondoc gears up to compete at Junior Wo...   \n",
       "31  Record-breaking attendance at FIBA World Cup 2023   \n",
       "11           Far Eastern stuns NU in men’s volleyball   \n",
       "12  Sandro Muhlach files sexual assault complaint ...   \n",
       "15       Bea Alonzo reflects on her toughest year yet   \n",
       "38  Bella Belen leads MVP race in UAAP women’s vol...   \n",
       "10  Five UAAP athletes named “Athletes of the Year...   \n",
       "44  Alden Richards reveals he battled depression i...   \n",
       "53   College Dean Arrested in Maguindanao Murder Case   \n",
       "26  Vice Ganda gushes over Ion Perez’s growth in s...   \n",
       "\n",
       "                                         gen_baseline  \n",
       "28  Young gymnast Maxine Bondoc aims high as she g...  \n",
       "31  Record-breaking World Cup attendance: Philippi...  \n",
       "11         Far Eastern defeats NU in men’s volleyball  \n",
       "12  Sandro Muhlach files sexual assault complaint ...  \n",
       "15  Actress Bea Alonzo opens up about how 2024 was...  \n",
       "38  Bella Belen leads MVP race in UAAP women’s vol...  \n",
       "10  UAAP names five “Athletes of the Year” for Sea...  \n",
       "44  Alden Richards reveals he battled depression i...  \n",
       "53  CIDG Arrests College Dean in Maguindanao for M...  \n",
       "26  Vice also shared how Perez positively influenc...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3b0b69b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(results_df[\"gen_neutral\"] == results_df[\"gen_punchy\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP_BART_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
