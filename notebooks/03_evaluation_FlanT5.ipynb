{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d64e246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating headlines...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/64 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "type object 'T5ForConditionalGeneration' has no attribute 'transformers-community/group-beam-search'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 49\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m style \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpunchy\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 49\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnum_beams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m              \u001b[49m\u001b[38;5;66;43;03m# Use 8 beams\u001b[39;49;00m\n\u001b[1;32m     53\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnum_beam_groups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Divide beams into 4 groups\u001b[39;49;00m\n\u001b[1;32m     54\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdiversity_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.5\u001b[39;49m\u001b[43m     \u001b[49m\u001b[38;5;66;43;03m# Penalize identical outputs significantly\u001b[39;49;00m\n\u001b[1;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m: \u001b[38;5;66;03m# neutral style, stick to high-fidelity generation\u001b[39;00m\n\u001b[1;32m     57\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[1;32m     58\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs, \n\u001b[1;32m     59\u001b[0m             max_new_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m,\n\u001b[1;32m     60\u001b[0m             num_beams\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m,\n\u001b[1;32m     61\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/envs/NLP_BART_env/lib/python3.10/site-packages/peft/peft_model.py:2374\u001b[0m, in \u001b[0;36mPeftModelForSeq2SeqLM.generate\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   2372\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_peft_forward_hooks(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   2373\u001b[0m         kwargs \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspecial_peft_forward_args}\n\u001b[0;32m-> 2374\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2375\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2376\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n",
      "File \u001b[0;32m~/miniconda3/envs/NLP_BART_env/lib/python3.10/site-packages/torch/utils/_contextlib.py:120\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 120\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/NLP_BART_env/lib/python3.10/site-packages/transformers/generation/utils.py:2386\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[0m\n\u001b[1;32m   2383\u001b[0m     decoding_method \u001b[38;5;241m=\u001b[39m custom_generate\n\u001b[1;32m   2384\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2385\u001b[0m     \u001b[38;5;66;03m# type() required to access the unbound class-level method\u001b[39;00m\n\u001b[0;32m-> 2386\u001b[0m     decoding_method \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mGENERATION_MODES_MAPPING\u001b[49m\u001b[43m[\u001b[49m\u001b[43mgeneration_mode\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2388\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_model_kwargs(model_kwargs\u001b[38;5;241m.\u001b[39mcopy())\n\u001b[1;32m   2389\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_generation_mode(generation_mode, generation_config, generation_mode_kwargs)\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'T5ForConditionalGeneration' has no attribute 'transformers-community/group-beam-search'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import evaluate\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
    "from peft import PeftModel, PeftConfig\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Setup\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "BASE_MODEL_ID = \"google/flan-t5-base\"\n",
    "STYLE_ADAPTER_PATH = \"../output/style_model_FlanT5\"\n",
    "\n",
    "# 1. Load Resources\n",
    "tokenizer = AutoTokenizer.from_pretrained(STYLE_ADAPTER_PATH)\n",
    "base_model = AutoModelForSeq2SeqLM.from_pretrained(BASE_MODEL_ID)\n",
    "base_model.resize_token_embeddings(len(tokenizer))\n",
    "model = PeftModel.from_pretrained(base_model, STYLE_ADAPTER_PATH)\n",
    "model.to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "# Load Test Data\n",
    "test_df = pd.read_csv('../data/processed/test.csv')\n",
    "\n",
    "# 2. Generation Loop\n",
    "print(\"Generating headlines...\")\n",
    "results = []\n",
    "styles = ['neutral', 'punchy']\n",
    "style_tokens = {'neutral': '<neutral>', 'punchy': '<punchy>'}\n",
    "\n",
    "for idx, row in tqdm(test_df.iterrows(), total=len(test_df)):\n",
    "    snippet = row['snippet']\n",
    "    \n",
    "    entry = {'snippet': snippet, 'ref_neutral': row['neutral'], \n",
    "             'ref_punchy': row['punchy']}\n",
    "    \n",
    "    # --- 1. Style-Controlled Model Generation ---\n",
    "    for style in styles:\n",
    "        input_text = f\"{style_tokens[style]} {snippet}\"\n",
    "        inputs = tokenizer(input_text, return_tensors=\"pt\").to(DEVICE)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            if style == 'punchy':\n",
    "                outputs = model.generate(\n",
    "                    **inputs, \n",
    "                    max_new_tokens=64,\n",
    "                    do_sample=True,             # Turn on sampling\n",
    "                    top_p=0.9,                  # Nucleus sampling (most common)\n",
    "                    temperature=0.8,            # Use a high temperature for creativity\n",
    "                )\n",
    "            else: # neutral style, stick to high-fidelity generation\n",
    "                outputs = model.generate(\n",
    "                    **inputs, \n",
    "                    max_new_tokens=64,\n",
    "                    num_beams=4,\n",
    "                )\n",
    "        \n",
    "        gen_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        entry[f'gen_{style}'] = gen_text\n",
    "        \n",
    "    # --- 2. Baseline Model Generation ---\n",
    "    # Baseline uses just the snippet as input, no style token\n",
    "    baseline_inputs = tokenizer(snippet, return_tensors=\"pt\").to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        baseline_outputs = base_model.generate(**baseline_inputs, max_new_tokens=64) # Uses base_model\n",
    "    \n",
    "    baseline_text = tokenizer.decode(baseline_outputs[0], skip_special_tokens=True)\n",
    "    entry['gen_baseline'] = baseline_text\n",
    "    \n",
    "    results.append(entry)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# 3. Metric 1: ROUGE Score\n",
    "rouge = evaluate.load('rouge')\n",
    "print(\"\\n--- ROUGE Scores ---\")\n",
    "\n",
    "# Style-Controlled Model Scores (Existing)\n",
    "for style in styles:\n",
    "    refs = results_df[f'ref_{style}'].tolist()\n",
    "    preds = results_df[f'gen_{style}'].tolist()\n",
    "    score = rouge.compute(predictions=preds, references=refs)\n",
    "    print(f\"Style Model <{style.upper()}>: {score}\")\n",
    "\n",
    "# Baseline Model Scores (NEW)\n",
    "baseline_preds = results_df['gen_baseline'].tolist()\n",
    "\n",
    "# Compare Baseline against NEUTRAL reference\n",
    "refs_neutral = results_df['ref_neutral'].tolist()\n",
    "score_baseline_neutral = rouge.compute(predictions=baseline_preds, references=refs_neutral)\n",
    "print(f\"Baseline Model vs. REF_NEUTRAL: {score_baseline_neutral}\")\n",
    "\n",
    "# Compare Baseline against PUNCHY reference\n",
    "refs_punchy = results_df['ref_punchy'].tolist()\n",
    "score_baseline_punchy = rouge.compute(predictions=baseline_preds, references=refs_punchy)\n",
    "print(f\"Baseline Model vs. REF_PUNCHY: {score_baseline_punchy}\")\n",
    "\n",
    "\n",
    "# 4. Metric 2: Style Accuracy (Simple Proxy Classifier)\n",
    "# We train a quick classifier on the TRAIN set to act as our evaluator\n",
    "print(\"\\n--- Training Proxy Style Classifier ---\")\n",
    "train_df = pd.read_csv('../data/processed/train.csv')\n",
    "train_texts = []\n",
    "train_labels = []\n",
    "\n",
    "# Unpack training data for classifier\n",
    "for _, row in train_df.iterrows():\n",
    "    train_texts.extend([row['neutral'], row['punchy']])\n",
    "    train_labels.extend(['neutral', 'punchy'])\n",
    "\n",
    "# 1. Split the human data for Classifier Training/Testing\n",
    "X_classifier_train, X_classifier_test, y_classifier_train, y_classifier_test = train_test_split(\n",
    "    train_texts, train_labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,5))\n",
    "X_train_vec = vectorizer.fit_transform(X_classifier_train)\n",
    "X_test_vec = vectorizer.transform(X_classifier_test)\n",
    "\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train_vec, y_classifier_train)\n",
    "\n",
    "# 2. Calculate Classifier Accuracy on its own test set\n",
    "y_pred = clf.predict(X_test_vec)\n",
    "classifier_acc = accuracy_score(y_classifier_test, y_pred)\n",
    "\n",
    "print(f\"Proxy Style Classifier Accuracy (on human data): {classifier_acc:.2%}\")\n",
    "\n",
    "# Evaluate Generated Headlines\n",
    "# Evaluate Generated Headlines\n",
    "print(\"\\n--- Evaluating Style Accuracy ---\")\n",
    "\n",
    "# Style-Controlled Model Evaluation (Existing)\n",
    "for style in styles:\n",
    "    gen_texts = results_df[f'gen_{style}'].tolist()\n",
    "    X_test = vectorizer.transform(gen_texts)\n",
    "    preds = clf.predict(X_test)\n",
    "    \n",
    "    # Calculate how many matched the requested style\n",
    "    matches = [1 if p == style else 0 for p in preds]\n",
    "    acc = sum(matches) / len(matches)\n",
    "    print(f\"Style Model Accuracy for requested style <{style}>: {acc:.2%}\")\n",
    "\n",
    "# Baseline Model Evaluation (NEW)\n",
    "baseline_gen_texts = results_df['gen_baseline'].tolist()\n",
    "X_test_baseline = vectorizer.transform(baseline_gen_texts)\n",
    "preds_baseline = clf.predict(X_test_baseline)\n",
    "\n",
    "# Calculate the distribution of predicted styles for the baseline\n",
    "from collections import Counter\n",
    "baseline_style_distribution = Counter(preds_baseline)\n",
    "total_count = len(preds_baseline)\n",
    "\n",
    "print(\"\\nBaseline Model Style Distribution:\")\n",
    "for style, count in baseline_style_distribution.items():\n",
    "    print(f\"  Predicted <{style}>: {count / total_count:.2%}\")\n",
    "\n",
    "# The baseline model isn't requested to be a specific style, so you evaluate its bias.\n",
    "\n",
    "# 5. Metric 3: Factuality (NLI)\n",
    "# Using a small NLI model to check entailment\n",
    "print(\"\\n--- Evaluating Factuality (NLI) ---\")\n",
    "nli_pipeline = pipeline(\"text-classification\", model=\"roberta-large-mnli\", device=0 if DEVICE==\"cuda\" else -1)\n",
    "\n",
    "def get_entailment_score(premise, hypothesis):\n",
    "    # NLI input format: \"Premise </s></s> Hypothesis\" (model specific, but pipeline handles pairs usually)\n",
    "    # roberta-large-mnli labels: CONTRADICTION, NEUTRAL, ENTAILMENT\n",
    "    # We pass text_pair to pipeline\n",
    "    result = nli_pipeline({'text': premise, 'text_pair': hypothesis})\n",
    "    # We want to know if it is NOT contradiction, or strictly entailment\n",
    "    # Let's track Entailment probability\n",
    "    return result['score'] if result['label'] == 'ENTAILMENT' else 0.0\n",
    "\n",
    "print(\"\\n--- Evaluating Factuality (NLI) ---\")\n",
    "\n",
    "# Style-Controlled Model Evaluation (Existing)\n",
    "for style in styles:\n",
    "    scores = []\n",
    "    for _, row in results_df.iterrows():\n",
    "        score = get_entailment_score(row['snippet'], row[f'gen_{style}'])\n",
    "        scores.append(score)\n",
    "    avg_fact = sum(scores)/len(scores)\n",
    "    print(f\"Style Model Average Entailment Score for <{style}>: {avg_fact:.4f}\")\n",
    "\n",
    "# Baseline Model Evaluation (NEW)\n",
    "baseline_scores = []\n",
    "for _, row in results_df.iterrows():\n",
    "    score = get_entailment_score(row['snippet'], row['gen_baseline'])\n",
    "    baseline_scores.append(score)\n",
    "avg_fact_baseline = sum(baseline_scores)/len(baseline_scores)\n",
    "print(f\"Baseline Model Average Entailment Score: {avg_fact_baseline:.4f}\")\n",
    "\n",
    "print(\"\\nEvaluation Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9876f401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>snippet</th>\n",
       "      <th>ref_neutral</th>\n",
       "      <th>ref_punchy</th>\n",
       "      <th>gen_neutral</th>\n",
       "      <th>gen_punchy</th>\n",
       "      <th>gen_baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Senate has approved a 10-fold increase in ...</td>\n",
       "      <td>Senate Approves P1 Billion Budget Increase for...</td>\n",
       "      <td>Senate Boosts Tourism: P1 Billion for DOT Bran...</td>\n",
       "      <td>Senate approves 10-fold increase in DOT budget...</td>\n",
       "      <td>DOT budget increases 10-fold for branding, mar...</td>\n",
       "      <td>Senate approves 10-fold increase in DOT budget...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>The Philippine men’s volleyball team swept Afg...</td>\n",
       "      <td>PH men’s volleyball beats Afghanistan for firs...</td>\n",
       "      <td>Spikers make history: PH sweeps Afghanistan in...</td>\n",
       "      <td>Philippine men’s volleyball sweeps Afghanistan...</td>\n",
       "      <td>Philippines volleyball team wins Asiad in Afgh...</td>\n",
       "      <td>Philippine men’s volleyball sweeps Afghanistan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>By the time he stepped down from the country’s...</td>\n",
       "      <td>Former President Duterte's Net Worth Increased...</td>\n",
       "      <td>P13.2M Richer: Duterte's Net Worth Jumps After...</td>\n",
       "      <td>Rodrigo Duterte’s net worth stands at P37.305 ...</td>\n",
       "      <td>Rodrigo Duterte’s Net Worth Hits P37.305 Milli...</td>\n",
       "      <td>Rodrigo Duterte’s net worth rises to P37.305 m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Organizers called on the Filipino spirit and u...</td>\n",
       "      <td>Campaign encourages national pride for PH FIBA...</td>\n",
       "      <td>PH rallies together — “Unite” for basketball’s...</td>\n",
       "      <td>FIBA World Cup organizers call on Filipino spi...</td>\n",
       "      <td>PH 'Unite': Filipino spirit, unity boost FIBA ...</td>\n",
       "      <td>PH’s Unite: Filipinos to shine in FIBA World C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Senator Jinggoy Estrada believes the K to 12 ...</td>\n",
       "      <td>Senator Estrada Expresses View that K to 12 Pr...</td>\n",
       "      <td>Estrada Slams K to 12: 'It's a Failure!'</td>\n",
       "      <td>Jinggoy Estrada says K to 12 education program...</td>\n",
       "      <td>Estrada dreads K-12 education program: No sanity</td>\n",
       "      <td>Estrada: K to 12 education program is a failure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>The 2023 FIBA World Cup saw record-breaking at...</td>\n",
       "      <td>FIBA World Cup games in PH see high attendance</td>\n",
       "      <td>PH fans flood the arenas — World Cup crowds se...</td>\n",
       "      <td>2023 FIBA World Cup sees record attendance</td>\n",
       "      <td>PH fans hold record attendance in FIBA World C...</td>\n",
       "      <td>PH’s FIBA World Cup attendance surges: PH’s PH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>An activist fishers’ group criticized the gove...</td>\n",
       "      <td>Fishers' Group Criticizes Three-Month Closed F...</td>\n",
       "      <td>Fishers Slam Visayan Sea Ban, Warn of Hunger a...</td>\n",
       "      <td>Activist fishers’ group criticizes Visayan Sea...</td>\n",
       "      <td>Activist fishers’ group criticizes Visayan Sea...</td>\n",
       "      <td>Activist fishers’ group criticizes Visayan Sea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>ABS-CBN and GMA stars made surprising crossove...</td>\n",
       "      <td>ABS-CBN and GMA actors now cross networks in n...</td>\n",
       "      <td>Network rivals no more — ABS-CBN &amp; GMA stars u...</td>\n",
       "      <td>ABS-CBN and GMA stars make surprising crossove...</td>\n",
       "      <td>ABS-CBN &amp; GMA stars make dramatic crossovers a...</td>\n",
       "      <td>ABS-CBN and GMA stars make surprising crossove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>The “Homestretch” episode highlighted the 2025...</td>\n",
       "      <td>“Homestretch” episode covers Batang Pinoy 2025...</td>\n",
       "      <td>Youth in motion: Batang Pinoy 2025 featured in...</td>\n",
       "      <td>Homestretch spotlights Batang Pinoy sports in ...</td>\n",
       "      <td>Homestretch highlights Batang Pinoy sports in ...</td>\n",
       "      <td>Homestretch highlights Batang Pinoy sports in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kanlaon Volcano on Negros Island released ash ...</td>\n",
       "      <td>Kanlaon Volcano Records New Ash Emission</td>\n",
       "      <td>Kanlaon Rumbles Anew: Ash Emission Reported</td>\n",
       "      <td>Kanlaon Volcano Releases Ash Again in Negros I...</td>\n",
       "      <td>Kanlaon Volcano Releases Ash Again in Negros I...</td>\n",
       "      <td>Kanlaon Volcano Releases Ash Again in Negros I...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              snippet  \\\n",
       "5   The Senate has approved a 10-fold increase in ...   \n",
       "62  The Philippine men’s volleyball team swept Afg...   \n",
       "0   By the time he stepped down from the country’s...   \n",
       "22  Organizers called on the Filipino spirit and u...   \n",
       "61   Senator Jinggoy Estrada believes the K to 12 ...   \n",
       "31  The 2023 FIBA World Cup saw record-breaking at...   \n",
       "43  An activist fishers’ group criticized the gove...   \n",
       "56  ABS-CBN and GMA stars made surprising crossove...   \n",
       "27  The “Homestretch” episode highlighted the 2025...   \n",
       "1   Kanlaon Volcano on Negros Island released ash ...   \n",
       "\n",
       "                                          ref_neutral  \\\n",
       "5   Senate Approves P1 Billion Budget Increase for...   \n",
       "62  PH men’s volleyball beats Afghanistan for firs...   \n",
       "0   Former President Duterte's Net Worth Increased...   \n",
       "22  Campaign encourages national pride for PH FIBA...   \n",
       "61  Senator Estrada Expresses View that K to 12 Pr...   \n",
       "31     FIBA World Cup games in PH see high attendance   \n",
       "43  Fishers' Group Criticizes Three-Month Closed F...   \n",
       "56  ABS-CBN and GMA actors now cross networks in n...   \n",
       "27  “Homestretch” episode covers Batang Pinoy 2025...   \n",
       "1            Kanlaon Volcano Records New Ash Emission   \n",
       "\n",
       "                                           ref_punchy  \\\n",
       "5   Senate Boosts Tourism: P1 Billion for DOT Bran...   \n",
       "62  Spikers make history: PH sweeps Afghanistan in...   \n",
       "0   P13.2M Richer: Duterte's Net Worth Jumps After...   \n",
       "22  PH rallies together — “Unite” for basketball’s...   \n",
       "61           Estrada Slams K to 12: 'It's a Failure!'   \n",
       "31  PH fans flood the arenas — World Cup crowds se...   \n",
       "43  Fishers Slam Visayan Sea Ban, Warn of Hunger a...   \n",
       "56  Network rivals no more — ABS-CBN & GMA stars u...   \n",
       "27  Youth in motion: Batang Pinoy 2025 featured in...   \n",
       "1         Kanlaon Rumbles Anew: Ash Emission Reported   \n",
       "\n",
       "                                          gen_neutral  \\\n",
       "5   Senate approves 10-fold increase in DOT budget...   \n",
       "62  Philippine men’s volleyball sweeps Afghanistan...   \n",
       "0   Rodrigo Duterte’s net worth stands at P37.305 ...   \n",
       "22  FIBA World Cup organizers call on Filipino spi...   \n",
       "61  Jinggoy Estrada says K to 12 education program...   \n",
       "31         2023 FIBA World Cup sees record attendance   \n",
       "43  Activist fishers’ group criticizes Visayan Sea...   \n",
       "56  ABS-CBN and GMA stars make surprising crossove...   \n",
       "27  Homestretch spotlights Batang Pinoy sports in ...   \n",
       "1   Kanlaon Volcano Releases Ash Again in Negros I...   \n",
       "\n",
       "                                           gen_punchy  \\\n",
       "5   DOT budget increases 10-fold for branding, mar...   \n",
       "62  Philippines volleyball team wins Asiad in Afgh...   \n",
       "0   Rodrigo Duterte’s Net Worth Hits P37.305 Milli...   \n",
       "22  PH 'Unite': Filipino spirit, unity boost FIBA ...   \n",
       "61   Estrada dreads K-12 education program: No sanity   \n",
       "31  PH fans hold record attendance in FIBA World C...   \n",
       "43  Activist fishers’ group criticizes Visayan Sea...   \n",
       "56  ABS-CBN & GMA stars make dramatic crossovers a...   \n",
       "27  Homestretch highlights Batang Pinoy sports in ...   \n",
       "1   Kanlaon Volcano Releases Ash Again in Negros I...   \n",
       "\n",
       "                                         gen_baseline  \n",
       "5   Senate approves 10-fold increase in DOT budget...  \n",
       "62  Philippine men’s volleyball sweeps Afghanistan...  \n",
       "0   Rodrigo Duterte’s net worth rises to P37.305 m...  \n",
       "22  PH’s Unite: Filipinos to shine in FIBA World C...  \n",
       "61    Estrada: K to 12 education program is a failure  \n",
       "31  PH’s FIBA World Cup attendance surges: PH’s PH...  \n",
       "43  Activist fishers’ group criticizes Visayan Sea...  \n",
       "56  ABS-CBN and GMA stars make surprising crossove...  \n",
       "27  Homestretch highlights Batang Pinoy sports in ...  \n",
       "1   Kanlaon Volcano Releases Ash Again in Negros I...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3b0b69b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(results_df[\"gen_neutral\"] == results_df[\"gen_punchy\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP_BART_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
